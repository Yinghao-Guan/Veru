from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import uvicorn
import re

# ğŸ‘‡ å¼•å…¥é™æµåº“
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

# Import Services
from services.llm_extractor import extract_citations_from_text
from services.openalex import search_paper_on_openalex
from services.google_search import verify_with_google_search
from services.auditor import verify_content_consistency
from services.semantic_scholar import search_paper_on_semantic_scholar

# ğŸ‘‡ åˆå§‹åŒ–é™æµå™¨ (åŸºäºè¯·æ±‚è€…çš„ IP åœ°å€)
limiter = Limiter(key_func=get_remote_address)

app = FastAPI(title="Veru Audit Engine")

# ğŸ‘‡ å°†é™æµå™¨æŒ‚è½½åˆ° App
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# CORS é…ç½®
origins = [
    "http://localhost:3000",
    "https://veru.app",
    "https://www.veru.app",
    "https://truvio.vercel.app",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

class AuditRequest(BaseModel):
    text: str


class AuditResult(BaseModel):
    citation_text: str
    status: str
    source: str
    metadata: dict
    message: str
    confidence: float


def get_clean_year(year_val):
    """Helper to extract 4-digit year string"""
    return "".join(filter(str.isdigit, str(year_val or "")))


@app.post("/api/audit", response_model=List[AuditResult])
@limiter.limit("10/minute")
def audit_citations(request: Request, body: AuditRequest):  # ğŸ‘ˆ ä¿®æ”¹è¿™é‡Œ
    """
    request: ç±»å‹ä¸º Requestï¼Œä¾› slowapi è·å– IP ä½¿ç”¨ã€‚
    body: Pydantic æ¨¡å‹ï¼ŒFastAPI ä¼šè‡ªåŠ¨æŠŠ JSON é‡Œçš„å†…å®¹æ”¾è¿›æ¥ã€‚
    """

    # ä» body ä¸­è·å– text
    citations = extract_citations_from_text(body.text)

    results = []

    for cit in citations:
        print(f"--- Auditing: {cit.title} ---")

        # OpenAlex æŸ¥è¯¢
        oa_result = search_paper_on_openalex(cit.title, cit.author)

        # åˆå§‹åŒ–æœ€ä½³ç»“æœä¸º OpenAlex
        best_result = oa_result
        source_name = "OpenAlex"

        # æ£€æŸ¥ OpenAlex çš„å¹´ä»½åŒ¹é…æƒ…å†µ
        cit_year = get_clean_year(cit.year)
        oa_year = get_clean_year(oa_result.get("year"))
        is_oa_year_match = (cit_year == oa_year) if (cit_year and oa_year) else True

        # === ç«ä¼˜é€»è¾‘ ===
        # è§¦å‘æ¡ä»¶ï¼šOpenAlex æ²¡æ‰¾åˆ°ï¼Œæˆ–è€…æ‰¾åˆ°äº†ä½†å¹´ä»½ä¸å¯¹
        if not oa_result["found"] or (oa_result["found"] and not is_oa_year_match):
            print(
                f"âš ï¸ OpenAlex result imperfect (Found: {oa_result['found']}, Year Match: {is_oa_year_match}). Checking Semantic Scholar...")

            s2_result = search_paper_on_semantic_scholar(cit.title, cit.author)

            if s2_result["found"]:
                s2_year = get_clean_year(s2_result.get("year"))
                is_s2_year_match = (cit_year == s2_year) if (cit_year and s2_year) else True

                # å†³ç­–ç‚¹ 1: OpenAlex æ²¡æ‰¾åˆ°ï¼ŒS2 æ‰¾åˆ°äº† -> ç”¨ S2
                if not oa_result["found"]:
                    print("âœ… Using Semantic Scholar (OpenAlex missed)")
                    best_result = s2_result
                    source_name = "Semantic Scholar"

                # å†³ç­–ç‚¹ 2: éƒ½æœ‰ç»“æœï¼Œä½† OpenAlex å¹´ä»½é”™ï¼ŒS2 å¹´ä»½å¯¹ -> ç”¨ S2
                elif not is_oa_year_match and is_s2_year_match:
                    print(f"âœ… Switching to Semantic Scholar (Better Year Match: {s2_year} vs OA {oa_year})")
                    best_result = s2_result
                    source_name = "Semantic Scholar"

                # å†³ç­–ç‚¹ 3: éƒ½æœ‰ç»“æœï¼Œå¹´ä»½éƒ½é”™ -> ä¿æŒ OpenAlex (æˆ–è€…å¯¹æ¯”å¼•ç”¨æ•°ï¼Œè¿™é‡Œæš‚ç•¥)

        # 3. æ‰§è¡Œå®¡è®¡ (ä½¿ç”¨æœ€ç»ˆé€‰å®šçš„ best_result)
        if best_result["found"]:
            print(f"Checking content consistency (Source: {source_name})...")
            consistency_check = verify_content_consistency(
                user_claim=cit.summary_intent + " " + " ".join(cit.specific_claims),
                real_abstract=best_result.get("abstract", "")
            )

            final_status = consistency_check.get("status", "REAL")
            explanation = consistency_check.get("reason", "Verification passed.")

            # å†æ¬¡æ£€æŸ¥å¹´ä»½ (é’ˆå¯¹æœ€ç»ˆé€‰å®šçš„ç»“æœ)
            db_year = get_clean_year(best_result.get("year"))

            if final_status == "REAL" and len(cit_year) == 4 and len(db_year) == 4:
                if cit_year != db_year:
                    if int(db_year) > int(cit_year):
                        explanation += f" (Note: Database lists a later version from {db_year}, please double check)."
                    else:
                        final_status = "MINOR_ERROR"
                        explanation += f" Note: Year mismatch (Cited: {cit_year}, DB: {db_year})."

            result = AuditResult(
                citation_text=cit.raw_text,
                status=final_status,
                source=source_name,
                confidence=consistency_check.get("confidence", 1.0),
                metadata=best_result,
                message=f"Citation found. Content Audit: {final_status} - {explanation}"
            )

        else:
            # 4. æœ€åçš„å…œåº•ï¼šGoogle Search
            print("âŒ Databases failed, switching to Google Search...")
            gs_result = verify_with_google_search(cit.title, cit.author, cit.summary_intent)

            status_map = {"REAL": "REAL", "FAKE": "FAKE", "MISMATCH": "MISMATCH", "UNVERIFIED": "UNVERIFIED"}
            g_status = status_map.get(gs_result.get("verdict"), "UNVERIFIED")

            result = AuditResult(
                citation_text=cit.raw_text,
                status=g_status,
                source="Google Search",
                confidence=gs_result.get("confidence", 0.0),
                metadata={"reason": gs_result.get("reason"), "info": gs_result.get("actual_paper_info")},
                message=f"Not found in academic databases. Google Search verdict: {g_status} - {gs_result.get('reason')}"
            )

        results.append(result)

    return results


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)